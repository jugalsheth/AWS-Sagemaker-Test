{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import boto3 ##boto3 is to read and write for aws as pandas is for files(my NASCENT understanding*)\n",
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "from sagemaker.session import s3_input, Session "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "us-east-2\n"
     ]
    }
   ],
   "source": [
    "bucket_name = 'bankappeg'\n",
    "my_region = boto3.session.Session().region_name\n",
    "#fetches the region my aws will work better in and i am located in\n",
    "print(my_region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S3 bucket created\n"
     ]
    }
   ],
   "source": [
    "s3 = boto3.resource('s3')\n",
    "try:\n",
    "    if my_region == 'us-east-2':\n",
    "        s3.create_bucket(Bucket = bucket_name,\n",
    "                         CreateBucketConfiguration\n",
    "                         ={'LocationConstraint':'us-east-2'})\n",
    "    print('S3 bucket created')\n",
    "except Exception as e:\n",
    "    print('Error: ',e)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nomenclature can be a problem\n",
    "AWS provides naming standards when naming an aws bucket.\n",
    "\n",
    "The bucket name can be between 3 and 63 characters long, and can contain only lower-case characters, numbers, periods, and dashes.\n",
    "\n",
    "Each label in the bucket name must start with a lowercase letter or number.\n",
    "\n",
    "The bucket name cannot contain underscores, end with a dash, have consecutive periods, or use dashes adjacent to periods.\n",
    "\n",
    "The bucket name cannot be formatted as an IP address (198.51.100.24).\n",
    "\n",
    "The name provided contains upper case letters, by switching to lower case letters the issue can be resolved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://bankappeg/xgboost-as-a-built-in-algo/output\n"
     ]
    }
   ],
   "source": [
    "prefix = 'xgboost-as-a-built-in-algo'\n",
    "output_path = 's3://{}/{}/output'.format(bucket_name,prefix)\n",
    "print(output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download data and saving in S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done : downloaded the bank csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import urllib\n",
    "\n",
    "try:\n",
    "    urllib.request.urlretrieve('https://d1.awsstatic.com/tmt/build-train-deploy-machine-learning-model-sagemaker/bank_clean.27f01fbbdf43271788427f3682996ae29ceca05d.csv','https://d1.awsstatic.com/tmt/build-train-deploy-machine-learning-model-sagemaker/bank_clean.27f01fbbdf43271788427f3682996ae29ceca05d.csv')\n",
    "    print('Done : downloaded the bank csv')\n",
    "except Exception as e:\n",
    "    print('Data loading error', e)\n",
    "                               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    datadf = pd.read_csv('./bank_cleaned.csv', index_col=0)\n",
    "    print('done')\n",
    "except Exception as e:\n",
    "    print('error ', e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>no_previous_contact</th>\n",
       "      <th>not_working</th>\n",
       "      <th>job_admin.</th>\n",
       "      <th>job_blue-collar</th>\n",
       "      <th>job_entrepreneur</th>\n",
       "      <th>job_housemaid</th>\n",
       "      <th>...</th>\n",
       "      <th>day_of_week_fri</th>\n",
       "      <th>day_of_week_mon</th>\n",
       "      <th>day_of_week_thu</th>\n",
       "      <th>day_of_week_tue</th>\n",
       "      <th>day_of_week_wed</th>\n",
       "      <th>poutcome_failure</th>\n",
       "      <th>poutcome_nonexistent</th>\n",
       "      <th>poutcome_success</th>\n",
       "      <th>y_no</th>\n",
       "      <th>y_yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  campaign  pdays  previous  no_previous_contact  not_working  \\\n",
       "0   56         1    999         0                    1            0   \n",
       "1   57         1    999         0                    1            0   \n",
       "\n",
       "   job_admin.  job_blue-collar  job_entrepreneur  job_housemaid  ...  \\\n",
       "0           0                0                 0              1  ...   \n",
       "1           0                0                 0              0  ...   \n",
       "\n",
       "   day_of_week_fri  day_of_week_mon  day_of_week_thu  day_of_week_tue  \\\n",
       "0                0                1                0                0   \n",
       "1                0                1                0                0   \n",
       "\n",
       "   day_of_week_wed  poutcome_failure  poutcome_nonexistent  poutcome_success  \\\n",
       "0                0                 0                     1                 0   \n",
       "1                0                 0                     1                 0   \n",
       "\n",
       "   y_no  y_yes  \n",
       "0     1      0  \n",
       "1     1      0  \n",
       "\n",
       "[2 rows x 61 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datadf.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "train_data, test_data = np.split(datadf.sample(frac=1\n",
    "                                               ,random_state=0),\n",
    "                                 [int(0.7 * len(datadf))])\n",
    "print(train_data.shape,test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'s3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n"
     ]
    }
   ],
   "source": [
    "# saving train and test in buckets\n",
    "import os\n",
    "pd.concat([train_data['y_yes'],\n",
    "           train_data.drop(['y_no','y_yes'],axis=1)],\n",
    "          axis=1).to_csv('train.csv',index= False,header=False)\n",
    "\n",
    "boto3.Session().resource('s3').Bucket(bucket_name).Object(os.path.join(prefix,'train/train.csv')).upload_file('train.csv')\n",
    "s3_input_train = sagemaker.s3_input(s3_data = 's3://{}/{}/train'.format(bucket_name,prefix),content_type= 'csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#'s3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'s3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n"
     ]
    }
   ],
   "source": [
    "#for test data\n",
    "pd.concat([test_data['y_yes'],test_data.drop(['y_yes','y_no'],axis=1)],axis=1).to_csv('test.csv',index = False,header = False)\n",
    "\n",
    "boto3.Session().resource('s3').Bucket(bucket_name).Object(os.path.join(prefix,'test/test.csv')).upload_file('test.csv')\n",
    "s3_input_test = sagemaker.s3_input(s3_data='s3://{}/{}/test'.format(bucket_name, prefix),content_type='csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build model xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'get_image_uri' method will be deprecated in favor of 'ImageURIProvider' class in SageMaker Python SDK v2.\n"
     ]
    }
   ],
   "source": [
    "#we use get_image_uri will help us fetch the inbuilt xgboost from a container and put it in a container\n",
    "\n",
    "container = get_image_uri(boto3.Session().region_name,'xgboost',repo_version='1.0-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize hyperparameters\n",
    "hyperparameters = {\n",
    "        \"max_depth\":\"5\",\n",
    "        \"eta\":\"0.2\",\n",
    "        \"gamma\":\"4\",\n",
    "        \"min_child_weight\":\"6\",\n",
    "        \"subsample\":\"0.7\",\n",
    "        \"objective\":\"binary:logistic\",\n",
    "        \"num_round\":50\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter image_name will be renamed to image_uri in SageMaker Python SDK v2.\n"
     ]
    }
   ],
   "source": [
    "estimator = sagemaker.estimator.Estimator(image_name=container, \n",
    "                                          hyperparameters=hyperparameters,\n",
    "                                          role=sagemaker.get_execution_role(),\n",
    "                                          train_instance_count=1, \n",
    "                                          train_instance_type='ml.m5.2xlarge', \n",
    "                                          train_volume_size=5, # 5 GB \n",
    "                                          output_path=output_path,\n",
    "                                          train_use_spot_instances=True,\n",
    "                                          train_max_run=300,\n",
    "                                          train_max_wait=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-09-08 22:54:58 Starting - Starting the training job...\n",
      "2020-09-08 22:55:00 Starting - Launching requested ML instances.........\n",
      "2020-09-08 22:56:44 Starting - Preparing the instances for training...\n",
      "2020-09-08 22:57:22 Downloading - Downloading input data\n",
      "2020-09-08 22:57:22 Training - Downloading the training image...\n",
      "2020-09-08 22:57:55 Uploading - Uploading generated training model\u001b[34mINFO:sagemaker-containers:Imported framework sagemaker_xgboost_container.training\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:Failed to parse hyperparameter objective value binary:logistic to Json.\u001b[0m\n",
      "\u001b[34mReturning the value itself\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34mINFO:sagemaker_xgboost_container.training:Running XGBoost Sagemaker in algorithm mode\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[22:57:51] 28831x59 matrix with 1701029 entries loaded from /opt/ml/input/data/train?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[22:57:51] 12357x59 matrix with 729063 entries loaded from /opt/ml/input/data/validation?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[34mINFO:root:Single node training.\u001b[0m\n",
      "\u001b[34mINFO:root:Train matrix has 28831 rows\u001b[0m\n",
      "\u001b[34mINFO:root:Validation matrix has 12357 rows\u001b[0m\n",
      "\u001b[34m[22:57:51] WARNING: /workspace/src/learner.cc:328: \u001b[0m\n",
      "\u001b[34mParameters: { num_round } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34m[0]#011train-error:0.10187#011validation-error:0.09970\u001b[0m\n",
      "\u001b[34m[1]#011train-error:0.10121#011validation-error:0.10010\u001b[0m\n",
      "\u001b[34m[2]#011train-error:0.10132#011validation-error:0.10010\u001b[0m\n",
      "\u001b[34m[3]#011train-error:0.10104#011validation-error:0.09962\u001b[0m\n",
      "\u001b[34m[4]#011train-error:0.10128#011validation-error:0.09938\u001b[0m\n",
      "\u001b[34m[5]#011train-error:0.10159#011validation-error:0.09938\u001b[0m\n",
      "\u001b[34m[6]#011train-error:0.10145#011validation-error:0.09954\u001b[0m\n",
      "\u001b[34m[7]#011train-error:0.10128#011validation-error:0.09938\u001b[0m\n",
      "\u001b[34m[8]#011train-error:0.10111#011validation-error:0.09954\u001b[0m\n",
      "\u001b[34m[9]#011train-error:0.10114#011validation-error:0.09921\u001b[0m\n",
      "\u001b[34m[10]#011train-error:0.10093#011validation-error:0.09913\u001b[0m\n",
      "\u001b[34m[11]#011train-error:0.10059#011validation-error:0.09905\u001b[0m\n",
      "\u001b[34m[12]#011train-error:0.10079#011validation-error:0.09938\u001b[0m\n",
      "\u001b[34m[13]#011train-error:0.10066#011validation-error:0.09986\u001b[0m\n",
      "\u001b[34m[14]#011train-error:0.10072#011validation-error:0.09946\u001b[0m\n",
      "\u001b[34m[15]#011train-error:0.10079#011validation-error:0.09962\u001b[0m\n",
      "\u001b[34m[16]#011train-error:0.10066#011validation-error:0.09986\u001b[0m\n",
      "\u001b[34m[17]#011train-error:0.10048#011validation-error:0.09986\u001b[0m\n",
      "\u001b[34m[18]#011train-error:0.10041#011validation-error:0.09946\u001b[0m\n",
      "\u001b[34m[19]#011train-error:0.10014#011validation-error:0.09970\u001b[0m\n",
      "\u001b[34m[20]#011train-error:0.10014#011validation-error:0.09913\u001b[0m\n",
      "\u001b[34m[21]#011train-error:0.09975#011validation-error:0.09954\u001b[0m\n",
      "\u001b[34m[22]#011train-error:0.09968#011validation-error:0.09897\u001b[0m\n",
      "\u001b[34m[23]#011train-error:0.09958#011validation-error:0.09889\u001b[0m\n",
      "\u001b[34m[24]#011train-error:0.09958#011validation-error:0.09913\u001b[0m\n",
      "\u001b[34m[25]#011train-error:0.09934#011validation-error:0.09897\u001b[0m\n",
      "\u001b[34m[26]#011train-error:0.09955#011validation-error:0.09930\u001b[0m\n",
      "\u001b[34m[27]#011train-error:0.09955#011validation-error:0.09897\u001b[0m\n",
      "\u001b[34m[28]#011train-error:0.09930#011validation-error:0.09921\u001b[0m\n",
      "\u001b[34m[29]#011train-error:0.09910#011validation-error:0.09913\u001b[0m\n",
      "\u001b[34m[30]#011train-error:0.09896#011validation-error:0.09897\u001b[0m\n",
      "\u001b[34m[31]#011train-error:0.09906#011validation-error:0.09889\u001b[0m\n",
      "\u001b[34m[32]#011train-error:0.09916#011validation-error:0.09913\u001b[0m\n",
      "\u001b[34m[33]#011train-error:0.09896#011validation-error:0.09930\u001b[0m\n",
      "\u001b[34m[34]#011train-error:0.09885#011validation-error:0.09930\u001b[0m\n",
      "\u001b[34m[35]#011train-error:0.09889#011validation-error:0.09921\u001b[0m\n",
      "\u001b[34m[36]#011train-error:0.09892#011validation-error:0.09921\u001b[0m\n",
      "\u001b[34m[37]#011train-error:0.09882#011validation-error:0.09913\u001b[0m\n",
      "\u001b[34m[38]#011train-error:0.09875#011validation-error:0.09913\u001b[0m\n",
      "\u001b[34m[39]#011train-error:0.09892#011validation-error:0.09897\u001b[0m\n",
      "\u001b[34m[40]#011train-error:0.09892#011validation-error:0.09938\u001b[0m\n",
      "\u001b[34m[41]#011train-error:0.09875#011validation-error:0.09938\u001b[0m\n",
      "\u001b[34m[42]#011train-error:0.09882#011validation-error:0.09954\u001b[0m\n",
      "\u001b[34m[43]#011train-error:0.09882#011validation-error:0.09946\u001b[0m\n",
      "\u001b[34m[44]#011train-error:0.09885#011validation-error:0.09930\u001b[0m\n",
      "\u001b[34m[45]#011train-error:0.09892#011validation-error:0.09930\u001b[0m\n",
      "\u001b[34m[46]#011train-error:0.09878#011validation-error:0.09930\u001b[0m\n",
      "\u001b[34m[47]#011train-error:0.09889#011validation-error:0.09954\u001b[0m\n",
      "\u001b[34m[48]#011train-error:0.09878#011validation-error:0.09962\u001b[0m\n",
      "\u001b[34m[49]#011train-error:0.09892#011validation-error:0.09921\u001b[0m\n",
      "\n",
      "2020-09-08 22:58:02 Completed - Training job completed\n",
      "Training seconds: 46\n",
      "Billable seconds: 12\n",
      "Managed Spot Training savings: 73.9%\n"
     ]
    }
   ],
   "source": [
    "estimator.fit({'train':s3_input_train,'validation':s3_input_test})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter image will be renamed to image_uri in SageMaker Python SDK v2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------!"
     ]
    }
   ],
   "source": [
    "xgb_predictor = estimator.deploy(initial_instance_count=1,instance_type='ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction on test data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12357,)\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.predictor import csv_serializer\n",
    "test_data_array = test_data.drop(['y_no', 'y_yes'], axis=1).values #we put the data into an array format\n",
    "xgb_predictor.content_type = 'text/csv' \n",
    "xgb_predictor.serializer = csv_serializer\n",
    "predictions = xgb_predictor.predict(test_data_array).decode('utf-8') # predict\n",
    "predictions_array = np.fromstring(predictions[1:], sep=',') #prediction into an array\n",
    "print(predictions_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Overall Classification Rate: 90.1%\n",
      "\n",
      "Predicted      No Purchase    Purchase\n",
      "Observed\n",
      "No Purchase    91% (10830)    33% (147)\n",
      "Purchase        9% (1079)     67% (301) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#taken from aws records\n",
    "cm = pd.crosstab(index=test_data['y_yes'], columns=np.round(predictions_array), rownames=['Observed'], colnames=['Predicted'])\n",
    "tn = cm.iloc[0,0]; fn = cm.iloc[1,0]; tp = cm.iloc[1,1]; fp = cm.iloc[0,1]; p = (tp+tn)/(tp+tn+fp+fn)*100\n",
    "print(\"\\n{0:<20}{1:<4.1f}%\\n\".format(\"Overall Classification Rate: \", p))\n",
    "print(\"{0:<15}{1:<15}{2:>8}\".format(\"Predicted\", \"No Purchase\", \"Purchase\"))\n",
    "print(\"Observed\")\n",
    "print(\"{0:<15}{1:<2.0f}% ({2:<}){3:>6.0f}% ({4:<})\".format(\"No Purchase\", tn/(tn+fn)*100,tn, fp/(tp+fp)*100, fp))\n",
    "print(\"{0:<16}{1:<1.0f}% ({2:<}){3:>7.0f}% ({4:<}) \\n\".format(\"Purchase\", fn/(tn+fn)*100,fn, tp/(tp+fp)*100, tp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deleting endpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'ResponseMetadata': {'RequestId': '71B37C10EF451E11',\n",
       "   'HostId': 'k7xOpFqEu3F99VKhSl/+j9SUz1ayGwVcwIDTBXnIIHDWUGAytoLXI6L6aO4LNBJs3VOBdvg9XTU=',\n",
       "   'HTTPStatusCode': 200,\n",
       "   'HTTPHeaders': {'x-amz-id-2': 'k7xOpFqEu3F99VKhSl/+j9SUz1ayGwVcwIDTBXnIIHDWUGAytoLXI6L6aO4LNBJs3VOBdvg9XTU=',\n",
       "    'x-amz-request-id': '71B37C10EF451E11',\n",
       "    'date': 'Wed, 09 Sep 2020 00:16:15 GMT',\n",
       "    'connection': 'close',\n",
       "    'content-type': 'application/xml',\n",
       "    'transfer-encoding': 'chunked',\n",
       "    'server': 'AmazonS3'},\n",
       "   'RetryAttempts': 0},\n",
       "  'Deleted': [{'Key': 'xgboost-as-a-built-in-algo/train/train.csv'},\n",
       "   {'Key': 'xgboost-as-a-built-in-algo/output/sagemaker-xgboost-2020-09-08-22-54-57-600/output/model.tar.gz'},\n",
       "   {'Key': 'xgboost-as-a-built-in-algo/test/test.csv'}]}]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sagemaker.Session().delete_endpoint(xgb_predictor.endpoint)\n",
    "bucket_to_delete = boto3.resource('s3').Bucket(bucket_name)\n",
    "bucket_to_delete.objects.all().delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
